{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "690fb7e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T04:39:11.181495300Z",
     "start_time": "2023-06-28T04:39:08.894914300Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import clip\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from math import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from IPython import display\n",
    "import time\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "242ef044",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T04:39:28.754881400Z",
     "start_time": "2023-06-28T04:39:28.737881600Z"
    }
   },
   "outputs": [],
   "source": [
    "def vision_attn_forward(self, x):\n",
    "    x = self.conv1(x)  # shape = [*, width, grid, grid]\n",
    "    x = x.reshape(x.shape[0], x.shape[1], -1)  # shape = [*, width, grid ** 2]\n",
    "    x = x.permute(0, 2, 1)  # shape = [*, grid ** 2, width]\n",
    "    x = torch.cat([self.class_embedding.to(x.dtype) + torch.zeros(x.shape[0], 1, x.shape[-1], dtype=x.dtype, device=x.device), x], dim=1)  # shape = [*, grid ** 2 + 1, width]\n",
    "    x = x + self.positional_embedding.to(x.dtype)\n",
    "    x = self.ln_pre(x)\n",
    "\n",
    "    x = x.permute(1, 0, 2)  # NLD -> LND\n",
    "    x,attn = self.transformer.transformer_attn_forward(x)\n",
    "    x = x.permute(1, 0, 2)  # LND -> NLD\n",
    "\n",
    "    x = self.ln_post(x[:, 0, :])\n",
    "\n",
    "    if self.proj is not None:\n",
    "        x = x @ self.proj\n",
    "\n",
    "    return x, attn\n",
    "\n",
    "def transformer_attn_forward(self, x):\n",
    "    z = x\n",
    "    attns = []\n",
    "    \n",
    "    for layer in self.resblocks:\n",
    "        z,a = layer.resblock_attn_forward(z)\n",
    "        attns.append(a)\n",
    "        \n",
    "    return z, attns\n",
    "\n",
    "def resblock_attn_forward(self, x):\n",
    "    attn_mask = self.attn_mask.to(dtype=x.dtype, device=x.device) if self.attn_mask is not None else None\n",
    "    \n",
    "    z = self.ln_1(x)\n",
    "    attn_pat, attn_weights = self.attn(z, z, z, need_weights=True, average_attn_weights = True, attn_mask=attn_mask)\n",
    "    attn_pat = attn_pat[0]\n",
    "\n",
    "    x = x + attn_pat\n",
    "    x = x + self.mlp(self.ln_2(x))\n",
    "    \n",
    "    return x, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b2dd7f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T04:39:31.304187900Z",
     "start_time": "2023-06-28T04:39:31.289187700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['RN50',\n 'RN101',\n 'RN50x4',\n 'RN50x16',\n 'RN50x64',\n 'ViT-B/32',\n 'ViT-B/16',\n 'ViT-L/14',\n 'ViT-L/14@336px']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d5f2f6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T04:39:39.112560200Z",
     "start_time": "2023-06-28T04:39:33.503394400Z"
    }
   },
   "outputs": [],
   "source": [
    "model, preprocess = clip.load(\"ViT-L/14@336px\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3068fd05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T04:39:56.041779600Z",
     "start_time": "2023-06-28T04:39:56.036779700Z"
    }
   },
   "outputs": [],
   "source": [
    "model.visual.vision_attn_forward = vision_attn_forward.__get__(model.visual)\n",
    "model.visual.transformer.transformer_attn_forward = transformer_attn_forward.__get__(model.visual.transformer)\n",
    "\n",
    "for layer in model.visual.transformer.resblocks:\n",
    "    layer.resblock_attn_forward = resblock_attn_forward.__get__(layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea61a7fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T04:39:58.443421900Z",
     "start_time": "2023-06-28T04:39:58.432914700Z"
    }
   },
   "outputs": [],
   "source": [
    "def attn_mask(frame, lastw):\n",
    "    with torch.no_grad():\n",
    "        with torch.autocast(\"cuda\"):\n",
    "            frame = Image.fromarray(frame[:480,80:80+480,:])\n",
    "            frame = frame.resize((336, 336), Image.NEAREST)\n",
    "            \n",
    "            z = preprocess(frame).unsqueeze(0).cuda()\n",
    "\n",
    "            z,attn = model.visual.vision_attn_forward(z)\n",
    "\n",
    "            #attn = torch.cat(attn,0).mean(0)[0,1:]\n",
    "            attn = torch.cat(attn,0)[-1,0,1:]\n",
    "            GRID = int(sqrt(attn.shape[0]))\n",
    "            attn = attn.view(1,1,GRID,GRID)\n",
    "            attn = F.upsample_bilinear(attn.view((1,1,GRID,GRID)), scale_factor=frame.width//GRID)\n",
    "            attn = attn.cpu().detach().numpy()[0,0]    \n",
    "            \n",
    "            im2 = np.array(frame).astype(np.float32)\n",
    "\n",
    "            w = np.clip( (attn/0.0025)**6,0,1)[:,:,np.newaxis]\n",
    "            \n",
    "            w = 0.25 * w + 0.75 * lastw\n",
    "            \n",
    "            im2 = w*im2 + np.mean(im2,axis=(0,1),keepdims=True)*(1-w)\n",
    "            im2 = np.clip(im2,0,255).astype(np.uint8)\n",
    "            \n",
    "            return im2, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92195cbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T04:41:40.049466Z",
     "start_time": "2023-06-28T04:40:00.077916400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dr GigglePuss\\PycharmProjects\\alife23\\venv\\lib\\site-packages\\torch\\nn\\functional.py:4070: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m(\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m      6\u001B[0m     ret, frame \u001B[38;5;241m=\u001B[39m vid\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m----> 8\u001B[0m     frame, lastw \u001B[38;5;241m=\u001B[39m \u001B[43mattn_mask\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlastw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m     cv2\u001B[38;5;241m.\u001B[39mimshow(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mframe\u001B[39m\u001B[38;5;124m'\u001B[39m, frame)\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;66;03m# Display the resulting frame\u001B[39;00m\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;66;03m#cv2.imshow('frame', frame)\u001B[39;00m\n\u001B[0;32m     12\u001B[0m       \n\u001B[0;32m     13\u001B[0m     \u001B[38;5;66;03m# the 'q' button is set as the\u001B[39;00m\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;66;03m# quitting button you may use any\u001B[39;00m\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;66;03m# desired button of your choice\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[6], line 16\u001B[0m, in \u001B[0;36mattn_mask\u001B[1;34m(frame, lastw)\u001B[0m\n\u001B[0;32m     14\u001B[0m attn \u001B[38;5;241m=\u001B[39m attn\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m,GRID,GRID)\n\u001B[0;32m     15\u001B[0m attn \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mupsample_bilinear(attn\u001B[38;5;241m.\u001B[39mview((\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m,GRID,GRID)), scale_factor\u001B[38;5;241m=\u001B[39mframe\u001B[38;5;241m.\u001B[39mwidth\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39mGRID)\n\u001B[1;32m---> 16\u001B[0m attn \u001B[38;5;241m=\u001B[39m \u001B[43mattn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy()[\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m0\u001B[39m]    \n\u001B[0;32m     18\u001B[0m im2 \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(frame)\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[0;32m     20\u001B[0m w \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mclip( (attn\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m0.0025\u001B[39m)\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m6\u001B[39m,\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m1\u001B[39m)[:,:,np\u001B[38;5;241m.\u001B[39mnewaxis]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "lastw = np.zeros((336, 336, 1))\n",
    "\n",
    "while(True):\n",
    "    ret, frame = vid.read()\n",
    "    \n",
    "    frame, lastw = attn_mask(frame, lastw)\n",
    "    cv2.imshow('frame', frame)\n",
    "    # Display the resulting frame\n",
    "    #cv2.imshow('frame', frame)\n",
    "      \n",
    "    # the 'q' button is set as the\n",
    "    # quitting button you may use any\n",
    "    # desired button of your choice\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "  \n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d364ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ab9f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
